{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Home \u00b6 The Iptables Add-on allows Splunk data administrators to map netfilter events to the CIM enabling the data to be used with other Splunk Apps. This Splunk Add-on is community driven. Any issues or feature requests may be submitted directly through Github . Assumptions \u00b6 This documentation assumes the following: You have a linux server with the appropriate firewall tools installed. You have a working Splunk environment. Basic understanding of Splunk, linux, and Firewalld/UFW/Iptables. About \u00b6 Info Description Version 1.3.8 - Splunkbase | GitHub Vendor Products REHL/CentOS - Firewalld, Ubuntu - UFW, built-in IPtables Add-on has a web UI No, this add-on does not include views. Get Started","title":"Home"},{"location":"#home","text":"The Iptables Add-on allows Splunk data administrators to map netfilter events to the CIM enabling the data to be used with other Splunk Apps. This Splunk Add-on is community driven. Any issues or feature requests may be submitted directly through Github .","title":"Home"},{"location":"#assumptions","text":"This documentation assumes the following: You have a linux server with the appropriate firewall tools installed. You have a working Splunk environment. Basic understanding of Splunk, linux, and Firewalld/UFW/Iptables.","title":"Assumptions"},{"location":"#about","text":"Info Description Version 1.3.8 - Splunkbase | GitHub Vendor Products REHL/CentOS - Firewalld, Ubuntu - UFW, built-in IPtables Add-on has a web UI No, this add-on does not include views. Get Started","title":"About"},{"location":"getting-started/prepare-logs-for-splunk/","text":"Prepare Logs for Splunk \u00b6 Optional Syslog Setup \u00b6 To simplify logging of linux firewall events it is recommended to utilize rsyslog, syslog-ng, or a similar tool to separate firewall events into a new file for Splunk to monitor. Refer to the vender specific documentation on the best-practices to accomplish this. A simple example using rsyslog is demonstrated below. Rsyslog Example # Example configuration file # /etc/rsyslog.d/10-iptables.conf # Log iptables log messages to file :msg,regex, \"IN=[^\\=]*OUT=\" /var/log/iptables.log # The following stops logging anything that matches the last rule to the original file being logged to. & stop Note Verify the created file will have sufficient privileges for Splunk to monitor the file. Log Prefix \u00b6 By default UFW and Firewalld use their own log prefixes: Firewall Prefix Example UFW [UFW *] [UFW ALLOW] IN= OUT=eth0 SRC=192.168.0.15 DST=192.168.0.16 LEN=76 TOS=0x10 PREC=0x00 TTL=64 ID=32137 DF PROTO=UDP SPT=36231 DPT=123 LEN=56 Firewalld *_DROP or *_REJECT FINAL_REJECT: IN=ens192 OUT= MAC= SRC=10.0.10.10 DST=10.0.10.21 LEN=328 TOS=0x00 PREC=0x00 TTL=57 ID=4162 PROTO=UDP SPT=53483 DPT=38811 LEN=308 If custom log prefixes are being used, additional setup may be required for this add-on to work appropriately. See Using Custom Log Prefixes in this documentation for more information.","title":"Prepare Logs for Splunk"},{"location":"getting-started/prepare-logs-for-splunk/#prepare-logs-for-splunk","text":"Optional","title":"Prepare Logs for Splunk"},{"location":"getting-started/prepare-logs-for-splunk/#syslog-setup","text":"To simplify logging of linux firewall events it is recommended to utilize rsyslog, syslog-ng, or a similar tool to separate firewall events into a new file for Splunk to monitor. Refer to the vender specific documentation on the best-practices to accomplish this. A simple example using rsyslog is demonstrated below. Rsyslog Example # Example configuration file # /etc/rsyslog.d/10-iptables.conf # Log iptables log messages to file :msg,regex, \"IN=[^\\=]*OUT=\" /var/log/iptables.log # The following stops logging anything that matches the last rule to the original file being logged to. & stop Note Verify the created file will have sufficient privileges for Splunk to monitor the file.","title":"Syslog Setup"},{"location":"getting-started/prepare-logs-for-splunk/#log-prefix","text":"By default UFW and Firewalld use their own log prefixes: Firewall Prefix Example UFW [UFW *] [UFW ALLOW] IN= OUT=eth0 SRC=192.168.0.15 DST=192.168.0.16 LEN=76 TOS=0x10 PREC=0x00 TTL=64 ID=32137 DF PROTO=UDP SPT=36231 DPT=123 LEN=56 Firewalld *_DROP or *_REJECT FINAL_REJECT: IN=ens192 OUT= MAC= SRC=10.0.10.10 DST=10.0.10.21 LEN=328 TOS=0x00 PREC=0x00 TTL=57 ID=4162 PROTO=UDP SPT=53483 DPT=38811 LEN=308 If custom log prefixes are being used, additional setup may be required for this add-on to work appropriately. See Using Custom Log Prefixes in this documentation for more information.","title":"Log Prefix"},{"location":"getting-started/where-to-install/","text":"Where to Install \u00b6 For detailed information on where to install Splunk Apps/add-ons, including best practices, can be found at Splunk Docs: About Installing Splunk add-ons Standalone Deployments \u00b6 Install this add-on to the single instance. For more information see Splunk Docs: Install add-on in a single-instance Splunk deployment Distributed Deployments \u00b6 Splunk Instance type Supported Required Comments Search Heads Yes Yes Install this add-on to all search heads. Indexers Yes Conditional Not required if heavy forwarders are used to collect data, required if not. Heavy Forwarders Yes Conditional Required, if HFs are used to collect this data source. Universal Forwarders Yes No This add-on does not contain any configurations for a Universal Forwarder. The installation steps for deploying Apps/add-ons in a distributed environment can be found at Splunk Docs: Install an add-on in a distributed Splunk deployment Distributed Deployment Compatibility \u00b6 Distributed deployment feature Supported Comments Search Head Clusters Yes You can install this add-on to a search head cluster. Indexer Clusters Yes You can install this add-on to a indexer cluster. Deployment Server Yes You can use a deployment server to push this add-on to Splunk Universal Forwarders. * For more information, see Splunk's documentation on installing Add-ons.","title":"Where to Install"},{"location":"getting-started/where-to-install/#where-to-install","text":"For detailed information on where to install Splunk Apps/add-ons, including best practices, can be found at Splunk Docs: About Installing Splunk add-ons","title":"Where to Install"},{"location":"getting-started/where-to-install/#standalone-deployments","text":"Install this add-on to the single instance. For more information see Splunk Docs: Install add-on in a single-instance Splunk deployment","title":"Standalone Deployments"},{"location":"getting-started/where-to-install/#distributed-deployments","text":"Splunk Instance type Supported Required Comments Search Heads Yes Yes Install this add-on to all search heads. Indexers Yes Conditional Not required if heavy forwarders are used to collect data, required if not. Heavy Forwarders Yes Conditional Required, if HFs are used to collect this data source. Universal Forwarders Yes No This add-on does not contain any configurations for a Universal Forwarder. The installation steps for deploying Apps/add-ons in a distributed environment can be found at Splunk Docs: Install an add-on in a distributed Splunk deployment","title":"Distributed Deployments"},{"location":"getting-started/where-to-install/#distributed-deployment-compatibility","text":"Distributed deployment feature Supported Comments Search Head Clusters Yes You can install this add-on to a search head cluster. Indexer Clusters Yes You can install this add-on to a indexer cluster. Deployment Server Yes You can use a deployment server to push this add-on to Splunk Universal Forwarders. * For more information, see Splunk's documentation on installing Add-ons.","title":"Distributed Deployment Compatibility"},{"location":"getting-started/configure-inputs/configure-inputs/","text":"Configure Splunk Input \u00b6 Objective : Set the sourcetype to linux:iptables in the inputs.conf file on the forwarder. Create a new index \u00b6 Optional Step If you do not wish to create a new index, skip to Splunk Universal Forwarder Configuration . Splunk stores data in indexes. This add-on may be configured to send to a custom event index instead of the default index, main. For more information and steps to create a new index, see Splunk Docs: Create events indexes . Purpose for Creating a new index \u00b6 The out of the box Splunk configuration stores all data in the default index, main. It is encouraged to create a new index to ensure optimal performance, for setting retention policies, and for providing stricter access controls. For more information about how Splunk indexes work with add-ons, see Splunk Docs: Add-ons and indexes . Splunk Universal Forwarder Configuration \u00b6 Download the latest Splunk Universal Forwarder ( UF ) appropriate for your server. Note Unless utilizing a syslog server, this UF should be installed on the same server that you wish to collect linux firewall events from. Install the UF according to Splunk Docs: Install the Universal Forwarder . Once installed the configurations can be made. The following is a sample inputs.conf that can be pushed using a deployment server or configured on the UF itself. inputs.conf [monitor:///var/log/iptables.log] disabled = 0 sourcetype = linux:iptables # optionally specify an index, if configured. index = osnixfw The above assumes the iptable logs have been split into a separate file (see Prepare Logs for Splunk ). If the iptable logs are mixed with other linux logs, then use the following sample configuration as a guide. Mixed Logs \u00b6 inputs.conf - for mixed logs [monitor:///var/log/syslog] disabled = 0 sourcetype = syslog # optionally specify an index, if configured. index = osnix Then create a local directory within this app and add a props.conf to transform the sourcetype to the correct sourcetype. local/props.conf - needed for mixed logs [syslog] TRANSFORMS-iptables_sourcetyper = iptables_sourcetyper This will enable a prebuilt transforms to automatically sourcetype these logs. Push the configuration to the forwarder, if using a deployment server, or restart the UF if configuring on the UF itself. Verify \u00b6 Verify the setup has completed successfully by navigating to Splunk web and running a search similar to the following: index=<chosen index> sourcetype=linux:iptables If you see data then you are all set! If you are not seeing your data, see Troubleshooting Monitoring Inputs .","title":"Configure Universal Forwarder"},{"location":"getting-started/configure-inputs/configure-inputs/#configure-splunk-input","text":"Objective : Set the sourcetype to linux:iptables in the inputs.conf file on the forwarder.","title":"Configure Splunk Input"},{"location":"getting-started/configure-inputs/configure-inputs/#create-a-new-index","text":"Optional Step If you do not wish to create a new index, skip to Splunk Universal Forwarder Configuration . Splunk stores data in indexes. This add-on may be configured to send to a custom event index instead of the default index, main. For more information and steps to create a new index, see Splunk Docs: Create events indexes .","title":"Create a new index"},{"location":"getting-started/configure-inputs/configure-inputs/#purpose-for-creating-a-new-index","text":"The out of the box Splunk configuration stores all data in the default index, main. It is encouraged to create a new index to ensure optimal performance, for setting retention policies, and for providing stricter access controls. For more information about how Splunk indexes work with add-ons, see Splunk Docs: Add-ons and indexes .","title":"Purpose for Creating a new index"},{"location":"getting-started/configure-inputs/configure-inputs/#splunk-universal-forwarder-configuration","text":"Download the latest Splunk Universal Forwarder ( UF ) appropriate for your server. Note Unless utilizing a syslog server, this UF should be installed on the same server that you wish to collect linux firewall events from. Install the UF according to Splunk Docs: Install the Universal Forwarder . Once installed the configurations can be made. The following is a sample inputs.conf that can be pushed using a deployment server or configured on the UF itself. inputs.conf [monitor:///var/log/iptables.log] disabled = 0 sourcetype = linux:iptables # optionally specify an index, if configured. index = osnixfw The above assumes the iptable logs have been split into a separate file (see Prepare Logs for Splunk ). If the iptable logs are mixed with other linux logs, then use the following sample configuration as a guide.","title":"Splunk Universal Forwarder Configuration"},{"location":"getting-started/configure-inputs/configure-inputs/#mixed-logs","text":"inputs.conf - for mixed logs [monitor:///var/log/syslog] disabled = 0 sourcetype = syslog # optionally specify an index, if configured. index = osnix Then create a local directory within this app and add a props.conf to transform the sourcetype to the correct sourcetype. local/props.conf - needed for mixed logs [syslog] TRANSFORMS-iptables_sourcetyper = iptables_sourcetyper This will enable a prebuilt transforms to automatically sourcetype these logs. Push the configuration to the forwarder, if using a deployment server, or restart the UF if configuring on the UF itself.","title":"Mixed Logs"},{"location":"getting-started/configure-inputs/configure-inputs/#verify","text":"Verify the setup has completed successfully by navigating to Splunk web and running a search similar to the following: index=<chosen index> sourcetype=linux:iptables If you see data then you are all set! If you are not seeing your data, see Troubleshooting Monitoring Inputs .","title":"Verify"},{"location":"getting-started/troubleshooting/troubleshoot-inputs/","text":"Troubleshoot Monitoring Inputs \u00b6 There is a variety of issues when getting new data into Splunk. Below are a few of the most common issues: Issue Description Solution Splunk cannot read the file If the user running Splunk (default is splunk ) cannot read the contents of the file, the data will not be sent to Splunk. log in as the Splunk user and verify the contents can be read. If not, update the permissions of the file to allow read access to the Splunk user. Incorrect timestamps Having the incorrect time setup on either the Splunk instance or the linux server may result in not ingesting the data. In Splunk web, try switching the time range to \"All Time\" when looking for the event data. If the data is found and the incorrect time is observed, update the servers to the correct time and consider utilizing a NTP server for proper time synchronization. Splunk Forwarder communication It is possible that the Splunk Universal Forwarder does not have a connection to the Splunk instance. Verify connection by running the following command on the universal forwarder: $SPLUNK_HOME/bin/splunk list forward-server . $SPLUNK_HOME is the installation directory. The output from this command will show active/inactive connections to the Splunk Instance. Alternatively the internal logs can be searched in Splunk Web. Run the following command on the search head: index=_internal source=*metrics.log* tcpin_connections | stats count by sourceIp . The output of this search will show a list of sources connecting to the Splunk Instance. For more troubleshooting steps, see Splunk Docs: Troubleshooting Data .","title":"Troubleshoot Monitoring Inputs"},{"location":"getting-started/troubleshooting/troubleshoot-inputs/#troubleshoot-monitoring-inputs","text":"There is a variety of issues when getting new data into Splunk. Below are a few of the most common issues: Issue Description Solution Splunk cannot read the file If the user running Splunk (default is splunk ) cannot read the contents of the file, the data will not be sent to Splunk. log in as the Splunk user and verify the contents can be read. If not, update the permissions of the file to allow read access to the Splunk user. Incorrect timestamps Having the incorrect time setup on either the Splunk instance or the linux server may result in not ingesting the data. In Splunk web, try switching the time range to \"All Time\" when looking for the event data. If the data is found and the incorrect time is observed, update the servers to the correct time and consider utilizing a NTP server for proper time synchronization. Splunk Forwarder communication It is possible that the Splunk Universal Forwarder does not have a connection to the Splunk instance. Verify connection by running the following command on the universal forwarder: $SPLUNK_HOME/bin/splunk list forward-server . $SPLUNK_HOME is the installation directory. The output from this command will show active/inactive connections to the Splunk Instance. Alternatively the internal logs can be searched in Splunk Web. Run the following command on the search head: index=_internal source=*metrics.log* tcpin_connections | stats count by sourceIp . The output of this search will show a list of sources connecting to the Splunk Instance. For more troubleshooting steps, see Splunk Docs: Troubleshooting Data .","title":"Troubleshoot Monitoring Inputs"},{"location":"guides/guide-custom-log-prefix/","text":"Custom Log Prefix \u00b6 If you wish to utilize custom log prefixes for use cases, additional setup will be needed for this add-on to properly identify events. This add-on uses the following to map events to their appropriate CIM -compliant action. The action field is important for the Network Traffic data model. If the log prefix does not match your events, the action will be \"unknown.\" Log Prefix Action *allow* allowed *block* blocked *drop* blocked *accept* allowed *reject* blocked *permit* allowed *deny* blocked *denied* blocked the wildcard character (*) is used to find any match with the contained value in the log_prefix field. Use your own log prefix \u00b6 It is recommended to use the log prefixes in the above table somewhere in your custom log prefix so no extra work is needed. Example \" allow _ssh_connections\" or \"telnet_ drop \" Add new log prefix definition \u00b6 If the above table defaults do not work for your use case, another lookup can be created with the correct values to fit your situation. Why use a new lookup file? If the existing lookup file is used, it will be overwritten during future updates. To preserve changes, a new lookup file must be created. It may be easiest to to utilize the linux command line to copy the lookup file, iptables_action.csv located in the lookups directory within this add-on. Example cp lookups/iptables_actions.csv lookups/iptables_custom_actions.csv From there you can update the file to fit your use case. Updating lookup example log_prefix,action *mycustom_allow*,allowed *custom_reject*,blocked *custom_drop*,blocked It is recommended to have the action field mapped to the Network Traffic datamodel action field (allowed, blocked, teardown). Wrapping the log_prefix field in wildcards (*) gives the flexibility of not having to specify exact values. Update transforms.conf \u00b6 After the custom lookup file has been updated, the transforms.conf file will need to be updated to the correct filename. Within the add-on, create a new file in local/transforms.conf (you may have to create the local directory). Next add the following to the file: local/transforms.conf [iptables_action_lookup] # If you followed the above example you would # set this to \"iptables_custom_actions.csv\" (without quotations). filename = <your_new_file.csv> Once the change has been made it may take a few minutes for the changes to take effect. If you don't want to wait you can append | extract reload=true to your Splunk search to force a reload of the configurations. You should now see the correct actions being populated and no longer will show \"unknown.\"","title":"Custom Log Prefix"},{"location":"guides/guide-custom-log-prefix/#custom-log-prefix","text":"If you wish to utilize custom log prefixes for use cases, additional setup will be needed for this add-on to properly identify events. This add-on uses the following to map events to their appropriate CIM -compliant action. The action field is important for the Network Traffic data model. If the log prefix does not match your events, the action will be \"unknown.\" Log Prefix Action *allow* allowed *block* blocked *drop* blocked *accept* allowed *reject* blocked *permit* allowed *deny* blocked *denied* blocked the wildcard character (*) is used to find any match with the contained value in the log_prefix field.","title":"Custom Log Prefix"},{"location":"guides/guide-custom-log-prefix/#use-your-own-log-prefix","text":"It is recommended to use the log prefixes in the above table somewhere in your custom log prefix so no extra work is needed. Example \" allow _ssh_connections\" or \"telnet_ drop \"","title":"Use your own log prefix"},{"location":"guides/guide-custom-log-prefix/#add-new-log-prefix-definition","text":"If the above table defaults do not work for your use case, another lookup can be created with the correct values to fit your situation. Why use a new lookup file? If the existing lookup file is used, it will be overwritten during future updates. To preserve changes, a new lookup file must be created. It may be easiest to to utilize the linux command line to copy the lookup file, iptables_action.csv located in the lookups directory within this add-on. Example cp lookups/iptables_actions.csv lookups/iptables_custom_actions.csv From there you can update the file to fit your use case. Updating lookup example log_prefix,action *mycustom_allow*,allowed *custom_reject*,blocked *custom_drop*,blocked It is recommended to have the action field mapped to the Network Traffic datamodel action field (allowed, blocked, teardown). Wrapping the log_prefix field in wildcards (*) gives the flexibility of not having to specify exact values.","title":"Add new log prefix definition"},{"location":"guides/guide-custom-log-prefix/#update-transformsconf","text":"After the custom lookup file has been updated, the transforms.conf file will need to be updated to the correct filename. Within the add-on, create a new file in local/transforms.conf (you may have to create the local directory). Next add the following to the file: local/transforms.conf [iptables_action_lookup] # If you followed the above example you would # set this to \"iptables_custom_actions.csv\" (without quotations). filename = <your_new_file.csv> Once the change has been made it may take a few minutes for the changes to take effect. If you don't want to wait you can append | extract reload=true to your Splunk search to force a reload of the configurations. You should now see the correct actions being populated and no longer will show \"unknown.\"","title":"Update transforms.conf"},{"location":"reference/reference-lookups/","text":"Lookup table files \u00b6 This add-on uses a few CSV lookup files to enrich the data. See below for more information on the lookups used. Lookup Lookup definition Description iptables_action.csv iptables_action_lookup Used to map events to their appropriate action. This utilizes default Firewalld and UFW log prefixes. Custom log prefixes will need to be setup for this to work see Using custom log prefixes for more information. iptables_frametypes.csv iptables_frametypes_lookup Maps Frame Type codes to their descriptive value. iptables_icmp_codes.csv iptables_icmp_codes_lookup Maps ICMP codes to their descriptive value. iptables_transport.csv iptables_transport_lookup Used to map the transport field to the CIM -compliant value.","title":"Lookup Tables"},{"location":"reference/reference-lookups/#lookup-table-files","text":"This add-on uses a few CSV lookup files to enrich the data. See below for more information on the lookups used. Lookup Lookup definition Description iptables_action.csv iptables_action_lookup Used to map events to their appropriate action. This utilizes default Firewalld and UFW log prefixes. Custom log prefixes will need to be setup for this to work see Using custom log prefixes for more information. iptables_frametypes.csv iptables_frametypes_lookup Maps Frame Type codes to their descriptive value. iptables_icmp_codes.csv iptables_icmp_codes_lookup Maps ICMP codes to their descriptive value. iptables_transport.csv iptables_transport_lookup Used to map the transport field to the CIM -compliant value.","title":"Lookup table files"},{"location":"reference/reference-sourcetypes/","text":"Sourcetype \u00b6 Sourcetype Description CIM Data Models linux:iptables Linux firewall events Network Traffic","title":"Sourectypes"},{"location":"reference/reference-sourcetypes/#sourcetype","text":"Sourcetype Description CIM Data Models linux:iptables Linux firewall events Network Traffic","title":"Sourcetype"},{"location":"reference/releases/","text":"Release Notes for the Linux Iptables Add-on for Splunk \u00b6 v1.3.8 Jul 8, 2022 \u00b6 New \u00b6 Added sample configuration for the syslog sourcetype if IPtable data is mixed with syslog data. Updated \u00b6 Updated log_prefix field extraction to consider log prefixes surrounded with quotes.","title":"Release Notes"},{"location":"reference/releases/#release-notes-for-the-linux-iptables-add-on-for-splunk","text":"","title":"Release Notes for the Linux Iptables Add-on for Splunk"},{"location":"reference/releases/#v138-jul-8-2022","text":"","title":"v1.3.8 Jul 8, 2022"},{"location":"reference/releases/#new","text":"Added sample configuration for the syslog sourcetype if IPtable data is mixed with syslog data.","title":"New"},{"location":"reference/releases/#updated","text":"Updated log_prefix field extraction to consider log prefixes surrounded with quotes.","title":"Updated"},{"location":"reference/releases/release-history/","text":"Release history for the Linux Iptables Add-on for Splunk \u00b6 The latest version of the Pi-hole DNS app for Splunk is version 1.3.8. See Release notes for the Linux Iptables Add-on for Splunk of the latest version. v1.3.7 Aug 20, 2021 \u00b6 fixed incorrect app value for UFW events - #5 updated regex for different UFW log formats - #8 v1.3.6 July 20, 2021 \u00b6 Notice This updated simplifies the number of sourcetypes down to a single sourcetype (linux:iptables). Any existing reports/alerts/views that are utilizing the old sourcetypes (\"linux:iptables:ufw\" or \"linux:iptables:firewalld\") will be impacted. Verify before updating to this version. added support for firewalld rich rules - #2 updated to only use the single sourcetype, 'linux:iptables' updated action lookup to use wildcards v1.3.5 Nov 2, 2020 \u00b6 Adding support for Splunk Cloud","title":"Release History"},{"location":"reference/releases/release-history/#release-history-for-the-linux-iptables-add-on-for-splunk","text":"The latest version of the Pi-hole DNS app for Splunk is version 1.3.8. See Release notes for the Linux Iptables Add-on for Splunk of the latest version.","title":"Release history for the Linux Iptables Add-on for Splunk"},{"location":"reference/releases/release-history/#v137-aug-20-2021","text":"fixed incorrect app value for UFW events - #5 updated regex for different UFW log formats - #8","title":"v1.3.7 Aug 20, 2021"},{"location":"reference/releases/release-history/#v136-july-20-2021","text":"Notice This updated simplifies the number of sourcetypes down to a single sourcetype (linux:iptables). Any existing reports/alerts/views that are utilizing the old sourcetypes (\"linux:iptables:ufw\" or \"linux:iptables:firewalld\") will be impacted. Verify before updating to this version. added support for firewalld rich rules - #2 updated to only use the single sourcetype, 'linux:iptables' updated action lookup to use wildcards","title":"v1.3.6 July 20, 2021"},{"location":"reference/releases/release-history/#v135-nov-2-2020","text":"Adding support for Splunk Cloud","title":"v1.3.5 Nov 2, 2020"}]}